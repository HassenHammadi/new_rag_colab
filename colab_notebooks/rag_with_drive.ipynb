{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG System with Google Drive Integration\n",
    "\n",
    "This notebook demonstrates how to use the RAG system with Google Drive integration for persistent storage of vector stores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu sentence-transformers transformers torch tqdm requests python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's clone the repository and install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (replace with your actual repository URL)\n",
    "!git clone https://github.com/yourusername/new_rag_colab.git\n",
    "\n",
    "# Add the repository to the Python path\n",
    "import sys\n",
    "sys.path.append('/content/new_rag_colab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "# Import RAG modules\n",
    "from new_rag_colab.processors.pdf_processor import PDFProcessor\n",
    "from new_rag_colab.processors.text_processor import TextProcessor\n",
    "from new_rag_colab.processors.json_processor import JSONProcessor\n",
    "from new_rag_colab.processors.csv_processor import CSVProcessor\n",
    "from new_rag_colab.chunkers.base_chunker import FixedSizeChunker\n",
    "from new_rag_colab.utils.embeddings import HuggingFaceEmbeddingProvider\n",
    "from new_rag_colab.vector_stores.drive_vector_store import DriveVectorStore\n",
    "from new_rag_colab.retrievers.base_retriever import SimpleRetriever\n",
    "from new_rag_colab.utils.drive_utils import DriveHandler\n",
    "from new_rag_colab.utils.colab_rag_pipeline import ColabRAGPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mount Google Drive\n",
    "\n",
    "Let's mount Google Drive to store our vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Drive handler\n",
    "drive_handler = DriveHandler(base_folder=\"RAG_vector_stores\")\n",
    "\n",
    "# Mount Google Drive\n",
    "drive_handler.mount_drive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create the RAG Pipeline\n",
    "\n",
    "Now, let's create the RAG pipeline with Google Drive integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embedding provider\n",
    "embedding_provider = HuggingFaceEmbeddingProvider(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "# Create the vector store with Drive integration\n",
    "vector_store = DriveVectorStore(\n",
    "    embedding_function=embedding_provider.get_embedding,\n",
    "    dimension=384,  # Dimension for all-MiniLM-L6-v2\n",
    "    drive_handler=drive_handler\n",
    ")\n",
    "\n",
    "# Create the chunker\n",
    "chunker = FixedSizeChunker(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# Create the retriever\n",
    "retriever = SimpleRetriever(vector_store, top_k=4)\n",
    "\n",
    "# Create processors for different file types\n",
    "processors = {\n",
    "    \"pdf\": PDFProcessor(extraction_method=\"pypdf\"),\n",
    "    \"text\": TextProcessor(),\n",
    "    \"json\": JSONProcessor(),\n",
    "    \"csv\": CSVProcessor()\n",
    "}\n",
    "\n",
    "# Create the RAG pipeline\n",
    "rag_pipeline = ColabRAGPipeline(\n",
    "    chunker=chunker,\n",
    "    vector_store=vector_store,\n",
    "    retriever=retriever,\n",
    "    processors=processors,\n",
    "    drive_handler=drive_handler,\n",
    "    use_query_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Upload and Process Files\n",
    "\n",
    "Let's upload and process some files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file upload widget\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload your files (PDF, TXT, JSON, CSV):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Process uploaded files\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"Processing {filename}...\")\n",
    "    file_path = Path(filename)\n",
    "    doc_ids = rag_pipeline.process_file(file_path)\n",
    "    print(f\"Added {len(doc_ids)} chunks from {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Vector Store to Google Drive\n",
    "\n",
    "Now, let's save our vector store to Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to save the vector store\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "vector_store_path = Path(temp_dir) / \"vector_store\"\n",
    "\n",
    "# Save the vector store to disk and Google Drive\n",
    "print(\"Saving vector store to Google Drive...\")\n",
    "rag_pipeline.save_vector_store(vector_store_path, drive_subfolder=\"my_vector_store\")\n",
    "print(\"Vector store saved to Google Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. List Available Vector Stores in Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available vector stores\n",
    "vector_stores = rag_pipeline.list_drive_vector_stores()\n",
    "print(\"Available vector stores in Google Drive:\")\n",
    "for store in vector_stores:\n",
    "    print(f\"- {store}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Vector Store from Google Drive\n",
    "\n",
    "Let's load a vector store from Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new temporary directory\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "vector_store_path = Path(temp_dir) / \"loaded_vector_store\"\n",
    "\n",
    "# Load the vector store from Google Drive\n",
    "print(\"Loading vector store from Google Drive...\")\n",
    "rag_pipeline.load_vector_store(vector_store_path, from_drive=True, drive_path=\"my_vector_store\")\n",
    "print(\"Vector store loaded from Google Drive.\")\n",
    "print(f\"Loaded {len(rag_pipeline.vector_store.documents)} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Query the RAG System\n",
    "\n",
    "Now, let's query our RAG system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query the RAG system\n",
    "def query_rag(query_text):\n",
    "    print(f\"Query: {query_text}\")\n",
    "    \n",
    "    # Get markdown response\n",
    "    markdown_response = rag_pipeline.query_with_markdown(query_text)\n",
    "    \n",
    "    # Display the response\n",
    "    from IPython.display import Markdown\n",
    "    return Markdown(markdown_response.replace(\"```markdown\\n\", \"\").replace(\"\\n```\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a query\n",
    "query_rag(\"What information can you find about machine learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interactive Query Interface\n",
    "\n",
    "Let's create an interactive query interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive query interface\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Create the text input widget\n",
    "query_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter your query here',\n",
    "    description='Query:',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "# Create the submit button\n",
    "submit_button = widgets.Button(\n",
    "    description='Submit',\n",
    "    button_style='primary',\n",
    "    tooltip='Submit query'\n",
    ")\n",
    "\n",
    "# Create the output widget\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define the submit button callback\n",
    "def on_submit_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        if query_input.value.strip():\n",
    "            display(query_rag(query_input.value))\n",
    "        else:\n",
    "            print(\"Please enter a query.\")\n",
    "\n",
    "# Register the callback with the button\n",
    "submit_button.on_click(on_submit_button_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "display(widgets.HBox([query_input, submit_button]))\n",
    "display(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
