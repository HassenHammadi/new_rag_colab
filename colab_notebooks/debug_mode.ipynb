{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG System Debugging Mode\n",
    "\n",
    "This notebook demonstrates how to use the debugging capabilities of the RAG system in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu sentence-transformers transformers torch tqdm requests python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's clone the repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/yourusername/new_rag_colab.git\n",
    "%cd new_rag_colab\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Logging\n",
    "\n",
    "Let's set up the debug logger with a more verbose logging level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from new_rag_colab.utils.debug_utils import debug_logger, DebugInspector\n",
    "\n",
    "# Set logging level to DEBUG for more detailed output\n",
    "debug_logger.logger.setLevel(logging.DEBUG)\n",
    "print(f\"Debug logger configured with level: {logging.getLevelName(debug_logger.logger.level)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_rag_colab.utils.drive_utils import DriveHandler\n",
    "\n",
    "# Create a Drive handler and mount Google Drive\n",
    "drive_handler = DriveHandler()\n",
    "drive_handler.mount_drive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create the RAG Pipeline with Debug Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_rag_colab.processors.pdf_processor import PDFProcessor\n",
    "from new_rag_colab.processors.text_processor import TextProcessor\n",
    "from new_rag_colab.chunkers.base_chunker import FixedSizeChunker\n",
    "from new_rag_colab.utils.embeddings import HuggingFaceEmbeddingProvider\n",
    "from new_rag_colab.vector_stores.drive_vector_store import DriveVectorStore\n",
    "from new_rag_colab.retrievers.base_retriever import SimpleRetriever\n",
    "from new_rag_colab.utils.colab_rag_pipeline import ColabRAGPipeline\n",
    "\n",
    "# Create components with debug mode enabled\n",
    "embedding_provider = HuggingFaceEmbeddingProvider(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "vector_store = DriveVectorStore(\n",
    "    embedding_function=embedding_provider.get_embedding,\n",
    "    dimension=384,\n",
    "    drive_handler=drive_handler,\n",
    "    debug=True  # Enable debug mode\n",
    ")\n",
    "\n",
    "chunker = FixedSizeChunker(chunk_size=1000, chunk_overlap=200)\n",
    "retriever = SimpleRetriever(vector_store)\n",
    "\n",
    "# Create processors\n",
    "processors = {\n",
    "    \"pdf\": PDFProcessor(),\n",
    "    \"text\": TextProcessor()\n",
    "}\n",
    "\n",
    "# Create the RAG pipeline\n",
    "rag_pipeline = ColabRAGPipeline(\n",
    "    chunker=chunker,\n",
    "    vector_store=vector_store,\n",
    "    retriever=retriever,\n",
    "    processors=processors,\n",
    "    drive_handler=drive_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Upload and Process Files with Debug Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Upload files\n",
    "print(\"Upload your files (PDF, TXT, JSON, CSV):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Process uploaded files with debug output\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"\\nProcessing {filename}...\")\n",
    "    try:\n",
    "        doc_ids = rag_pipeline.process_file(filename)\n",
    "        print(f\"Added {len(doc_ids)} chunks from {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inspect Vector Store Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get debug information about the vector store\n",
    "debug_info = vector_store.get_debug_info()\n",
    "\n",
    "print(f\"Vector Store Debug Information:\")\n",
    "print(f\"- Document count: {debug_info['document_count']}\")\n",
    "print(f\"- Embedding dimension: {debug_info['dimension']}\")\n",
    "print(f\"- FAISS index size: {debug_info['index_size']}\")\n",
    "print(f\"\\nMetadata fields: {', '.join(debug_info['metadata_fields'])}\")\n",
    "print(f\"\\nSource files: {', '.join(debug_info['source_files'])}\")\n",
    "print(f\"\\nSource types: {', '.join(debug_info['source_types'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inspect Document Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first few documents\n",
    "print(f\"Vector store contains {len(vector_store.documents)} documents\")\n",
    "print(\"\\nSample documents:\")\n",
    "\n",
    "for i, doc in enumerate(vector_store.documents[:3]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"- ID: {doc.get('id', 'unknown')}\")\n",
    "    print(f\"- Metadata: {doc.get('metadata', {})}\")\n",
    "    content = doc.get('content', '')\n",
    "    print(f\"- Content: {content[:100]}...\" if len(content) > 100 else f\"- Content: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Vector Store with Debug Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a temporary directory\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "vector_store_path = Path(temp_dir) / \"debug_vector_store\"\n",
    "\n",
    "# Save the vector store with debug output\n",
    "print(\"Saving vector store to Google Drive...\")\n",
    "vector_store.save(vector_store_path, drive_subfolder=\"debug_vector_store\")\n",
    "print(\"Vector store saved to Google Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Load Vector Store with Debug Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new vector store\n",
    "new_vector_store = DriveVectorStore(\n",
    "    embedding_function=embedding_provider.get_embedding,\n",
    "    dimension=384,\n",
    "    drive_handler=drive_handler,\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "# Create a new temporary directory\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "load_path = Path(temp_dir) / \"loaded_vector_store\"\n",
    "\n",
    "# Load the vector store with debug output\n",
    "print(\"Loading vector store from Google Drive...\")\n",
    "new_vector_store.load(load_path, from_drive=True, drive_path=\"debug_vector_store\")\n",
    "print(\"Vector store loaded from Google Drive.\")\n",
    "\n",
    "# Verify the loaded vector store\n",
    "print(f\"Loaded {len(new_vector_store.documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Query with Debug Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new retriever with the loaded vector store\n",
    "new_retriever = SimpleRetriever(new_vector_store)\n",
    "\n",
    "# Create a new RAG pipeline\n",
    "new_rag_pipeline = ColabRAGPipeline(\n",
    "    chunker=chunker,\n",
    "    vector_store=new_vector_store,\n",
    "    retriever=new_retriever,\n",
    "    processors=processors,\n",
    "    drive_handler=drive_handler\n",
    ")\n",
    "\n",
    "# Query with debug output\n",
    "query = \"What information can you find in my documents?\"\n",
    "print(f\"Query: {query}\")\n",
    "results = new_rag_pipeline.query(query)\n",
    "\n",
    "print(f\"\\nFound {len(results)} results:\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nResult {i+1} (score: {result.get('score', 0):.4f}):\")\n",
    "    print(f\"Source: {result.get('metadata', {}).get('source_file', 'unknown')}\")\n",
    "    content = result.get('content', '')\n",
    "    print(f\"Content: {content[:100]}...\" if len(content) > 100 else f\"Content: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Debug Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DebugInspector to inspect objects\n",
    "print(\"Vector Store Inspection:\")\n",
    "DebugInspector.print_vector_store_info(vector_store)\n",
    "\n",
    "print(\"\\nRetriever Inspection:\")\n",
    "DebugInspector.print_object_info(retriever, \"Retriever\")\n",
    "\n",
    "print(\"\\nChunker Inspection:\")\n",
    "DebugInspector.print_object_info(chunker, \"Chunker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Performance Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple queries and measure performance\n",
    "queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How does neural network work?\",\n",
    "    \"What are the benefits of deep learning?\",\n",
    "    \"Explain natural language processing\"\n",
    "]\n",
    "\n",
    "print(\"Running performance test...\\n\")\n",
    "\n",
    "for query in queries:\n",
    "    debug_logger.start_timer(f\"query_{query[:20]}\")\n",
    "    results = new_rag_pipeline.query(query)\n",
    "    duration = debug_logger.end_timer(f\"query_{query[:20]}\")\n",
    "    print(f\"Query: '{query}' - {len(results)} results in {duration:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
